So the notion of sustainable pace is pretty simple. There is a optimal rate of throughput of hours applied of work, basically 14, where for the hours put in, we're going to get the most amount of work out of and the best throughput. If we're lower than that, obviously, we're gonna get lower throughput. But there's some phenomena, if we go higher than that, we'll get a spike in throughput, we'll get more work out of that team. But over a period of time, that will actually diminish. And what ends up happening is, the team now is working additional hours for the same level of throughput that they had back when they were working, let's say 40 hours a week. So as a project managers and iteration manager, as a member of the team, you want to figure out, what is that optimal level for the team, and then plan in accord with that optimization mistake that we often make is a project doesn't look like he's gonna make his deadline. So we asked the team to increase their hours and thereby increase their velocity or, you know, reduce their cycle time. And that temporary phenomena doesn't pay off in the long run. So draw a bit of a graph to kind of show a typical scenario, right. So just here we have time. And there's a couple of different metrics that I'm going to have along the y axis. So this is our iterations. And then here, we're going to have hours.

So the time that the team actually puts in, we're going to have velocity, the amount of work that they get done over that period of time.

And we're going to have quality. Some quantifiable metric for quality of the code, this can be cyclomatic complexity, it could be test coverage, it could be some heuristic that includes multiple data points. But regardless, there's there are ways of ascertain the quality of our code, right. So project, kind of, here's what ends up happening, a lot of cases, we've got a team that's putting in fairly consistently the same amount of hours every week. And lo and behold, based on those hours, we're getting relatively consistent velocity. And we're getting relatively consistent quality. But we decided, we determined that this credit is gonna is falling behind. And we need the team to just, you know, put in a little more effort. So what ends up happening is, for a couple of iterations, or for some relatively finite period of time, we actually increase the velocity are the hours applied. And velocity actually goes up. So the team is now delivering more based on this new amount of hours. But sneakily what we don't notice, oftentimes, what we don't notice is quality begins to suffer pretty quickly. And as that quality suffers, this is internal quality of the code, its quality of communications, and not just code, but I'm using a code metric just to kind of exemplify here. As this begins to suffer, say, we stay at this pace.

Quality now is going to continue to diminish. And guess what's gonna happen to our velocity, our ability to actually get the work done is going to start to diminish.

Until eventually, what's happening is we're working, you know, what is this, maybe it's only 10%. But you know, 20 to 30%. We're working all these additional hours, and we actually returned to our same throughput. But our quality is diminishing. So we made it we decided to make a sacrifice, we got a temporary result. And really, the only way to actually fix this. A lot of teams what they do is then they go to put in more hours, more hours more hours, and then the phenomenon just continues right? Really the only way to fix this is to get this team back to whatever is their optimal sustainable pace, allow them to recover from this and then settle back into what is their standard velocity. There are ways of improving a team's velocity, but increasing the pace is not it
